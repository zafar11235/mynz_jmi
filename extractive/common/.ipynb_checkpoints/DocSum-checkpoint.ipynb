{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extractive Summerization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from collections import Counter\n",
    "from itertools import combinations\n",
    "from math import sqrt\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from nltk import word_tokenize, sent_tokenize, FreqDist,pos_tag\n",
    "from nltk.corpus import stopwords, wordnet as wn\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from operator import itemgetter\n",
    "import re\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convergence threshold is the maximum error in score convergence of TextRank\n",
    "CONVERGENCE_THRESHOLD = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set of all nouns\n",
    "NOUNS = {x.name().split('.', 1)[0] for x in wn.all_synsets('n')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Document():\n",
    "    '''\n",
    "    The master class for our Document Summerization module.\n",
    "    Incorporates all features related to Document\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, document):\n",
    "        self.document = document\n",
    "        self.sents = sent_tokenize(self.document)\n",
    "        self.word_freq = FreqDist(clean(self.document))\n",
    "        self.graph = None\n",
    "        self.params = { 'thresh': 0.0\n",
    "            \n",
    "        }\n",
    "        \n",
    "                \n",
    "    def __str__(self):\n",
    "        return self.document\n",
    "    \n",
    "    \n",
    "    def statistical_sim(self, sent1, sent2):\n",
    "        '''\n",
    "        Statistical similarity between sentences\n",
    "        based on the cosine method\n",
    "        Returns: float (the cosine similarity b/w sent1 and sent2)\n",
    "        '''\n",
    "        sent_token1 = Counter(sent1)\n",
    "        sent_token2 = Counter(sent2)\n",
    "        \n",
    "        intxn = set(sent_token1) & set(sent_token2)\n",
    "        numerator = sum([sent_token1[x] * sent_token2[x] for x in intxn])\n",
    "        \n",
    "        mod1 = sum([sent_token1[x]**2 for x in sent_token1.keys()])\n",
    "        mod2 = sum([sent_token2[x]**2 for x in sent_token2.keys()])\n",
    "        denominator = sqrt(mod1)*sqrt(mod2)\n",
    "        \n",
    "        if not denominator:\n",
    "            return 0.0\n",
    "\n",
    "        return float(numerator)/denominator\n",
    "    \n",
    "    \n",
    "    def semantic_sim(self, sent1, sent2):\n",
    "        '''\n",
    "        A semantic similarity score between two sentences\n",
    "        based on WordNet\n",
    "        Returns: float (the semantic similarity measure)\n",
    "        '''\n",
    "        score = 0\n",
    "        sent1 = [word for word in sent1 if word in NOUNS]\n",
    "        sent2 = [word for word in sent2 if word in NOUNS]\n",
    "        for t1 in sent1:\n",
    "            for t2 in sent2:\n",
    "                score += semantic_score(t1,t2)\n",
    "        try:\n",
    "            return score/(len(sent1 + sent2))  \n",
    "        else:\n",
    "            return 10000\n",
    "    \n",
    "    \n",
    "    def construct_graph(self):\n",
    "        '''\n",
    "        Constructs the word similarity graph\n",
    "        '''\n",
    "        connected = []\n",
    "        for pair in combinations(self.sents, 2):\n",
    "            cpair = clean(pair[0]), clean(pair[1])\n",
    "            weight = self.statistical_sim(*cpair) + \\\n",
    "                     self.semantic_sim(*cpair)\n",
    "            connected.append((pair[0], pair[1], weight))\n",
    "        self.graph = draw_graph(connected, self.params['thresh'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "def clean(sent):\n",
    "    '''\n",
    "    A utility function that returns a a list of words in a sentence\n",
    "    after cleaning it. Gets rid off uppper-case, punctuations, \n",
    "    stop words, etc.\n",
    "    Returns: list (a list of cleaned words in sentence)\n",
    "    '''\n",
    "    words =  sent.lower() \n",
    "    words = re.findall(r'\\w+', words,flags = re.UNICODE | re.LOCALE) \n",
    "    imp_words = filter(lambda x: x not in stopwords.words('english'), words)\n",
    "    return imp_words\n",
    "        \n",
    "def semantic_score(word1, word2):\n",
    "    '''\n",
    "    Semantic score between two words based on WordNet\n",
    "    Returns: float (the semantic score between word1 and word2)\n",
    "    '''\n",
    "    try:\n",
    "        w1 = wn.synset('%s.n.01'%(word1))\n",
    "        w2 = wn.synset('%s.n.01'%(word2))\n",
    "        return wn.path_similarity(w1,w2,simulate_root = False)\n",
    "    except:\n",
    "        return 0\n",
    "    \n",
    "def draw_graph(connected, thresh):\n",
    "    '''\n",
    "    Draws graph as per weights and puts edges if \n",
    "    weight exceed the given thresh\n",
    "    Returns: networkx Graph (nodes are sentences and edges\n",
    "             are statistical and semantic relationships)\n",
    "    '''\n",
    "    nodes = set([n1 for n1, n2, n3 in connected] + \\\n",
    "                [n2 for n1, n2, n3 in connected])\n",
    "    G=nx.Graph()\n",
    "    for node in nodes:\n",
    "        G.add_node(node)\n",
    "    for edge in connected:\n",
    "        if edge[2] > thresh:\n",
    "            G.add_edge(edge[0], edge[1],weight = edge[2])\n",
    "    plt.figure(figsize=(8,8))\n",
    "    pos = nx.spring_layout(G)\n",
    "    nx.draw(G,node_color='#A0CBE2', edge_color='orange',width=1,with_labels=False)\n",
    "    plt.show()\n",
    "    return G\n",
    "    \n",
    "def textrank_weighted(graph, initial_value=None, damping=0.85):\n",
    "    '''\n",
    "    Calculates PageRank for an undirected graph\n",
    "    Returns: A list of tuples representing sentences and respective\n",
    "    scores in descending order\n",
    "    '''\n",
    "    if initial_value == None: initial_value = 1.0 / len(graph.nodes())\n",
    "    scores = dict.fromkeys(graph.nodes(), initial_value)\n",
    "\n",
    "    iteration_quantity = 0\n",
    "    for iteration_number in xrange(100):\n",
    "        iteration_quantity += 1\n",
    "        convergence_achieved = 0\n",
    "        for i in graph.nodes():\n",
    "            rank = 1 - damping\n",
    "            for j in graph.neighbors(i):\n",
    "                neighbors_sum = sum([graph.get_edge_data(j, k)['weight'] for k in graph.neighbors(j)])\n",
    "                rank += damping * scores[j] * graph.get_edge_data(j, i)['weight'] / neighbors_sum\n",
    "\n",
    "            if abs(scores[i] - rank) <= CONVERGENCE_THRESHOLD:\n",
    "                convergence_achieved += 1\n",
    "\n",
    "            scores[i] = rank\n",
    "\n",
    "        if convergence_achieved == len(graph.nodes()):\n",
    "            break\n",
    "    return sorted(scores.items(), key=itemgetter(1), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = '''\n",
    "burning tires tear gas and clashes with riot police the ugly scenes that come with workers strikes are all too familiar in france a country constantly trying to balance its culture of workers rights with a more efficient economy.\n",
    "such scenes are being played out across the country friday as unions have called for workers to step up protests that have for the past week crippled parts of france.\n",
    "employees of oil refineries nuclear power plants and some public transportation have left one in three gas stations dry forcing vehicles to search for well stocked stations and causing long lines at the pump.\n",
    "people are now hoarding gas worried that it may be some time until supply levels are back to normal.\n",
    "the workers are protesting a labor reform bill put forward by the government that will make it easier for companies to hire and fire employees.\n",
    "the governments argument is that the strict laws that make french workers among the best protected in the world leave companies in a difficult position where they cant take on new staff.\n",
    "french prime minister manuel valls told local media on thursday that he might be willing to modify some of the proposals giving hope to french people that the protests and fuel shortages may soon stop.\n",
    "but workers unions friday responded with a call to step up rallies and blockades demanding a complete withdrawal of the bill.\n",
    "we call for the continuation and intensification of protests a group of unions behind the protests said in a statement.\n",
    "the governments violent words its contempt for the social movement and its refusal to withdraw this bill reinforces our commitment it said.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = '/Users/najeebkhan/Desktop/mynz_jmi/rnn/twitter/tweet.txt'\n",
    "with open(data,\"r\") as fp:\n",
    "    s = fp.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110592\n"
     ]
    }
   ],
   "source": [
    "print len(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = Document(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "integer division or modulo by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-31fa660b025c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstruct_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-c07dc91a4436>\u001b[0m in \u001b[0;36mconstruct_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mpair\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mcpair\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatistical_sim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcpair\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m                      \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msemantic_sim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcpair\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m             \u001b[0mconnected\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdraw_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnected\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'thresh'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-c07dc91a4436>\u001b[0m in \u001b[0;36msemantic_sim\u001b[0;34m(self, sent1, sent2)\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mt2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msent2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                 \u001b[0mscore\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msemantic_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msent2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: integer division or modulo by zero"
     ]
    }
   ],
   "source": [
    "a.construct_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'nodes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-a132a1ba4687>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtextrank_weighted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-85c49a97cc1a>\u001b[0m in \u001b[0;36mtextrank_weighted\u001b[0;34m(graph, initial_value, damping)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mscores\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdescending\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     '''\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0minitial_value\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minitial_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'nodes'"
     ]
    }
   ],
   "source": [
    "x = textrank_weighted(a.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
